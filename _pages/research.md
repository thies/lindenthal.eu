---
permalink: /research/
title: "Research"
---

### Working Paper

* Eichholtz, P.; Lindenthal T. and M. Korevaar <a class="external-link" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3418495" target="_self" title=""><span class="external-link">“Growth and Predictability of Urban Housing Rents”</span></a>

  - *Abstract:* This paper studies urban rental prices for half a millennium (1500–2020) and seven cities: Amsterdam, Antwerp, Bruges, Brussels, Ghent, London, and Paris. Based on a dataset of 436,000 rental cash flow observations, we build continuous annual indices of housing rents, which we employ to study the long-term developments in rental cash flows, as well as their predictability. We find that real rent growth has been limited, but with large differences across cities: average annual growth rates range between 0.12 percent for the Belgian cities to 0.30 percent for Paris. At the market level, we show that sluggish supply adjustment implies that past population growth negatively predicts current rental growth. At the individual asset level, we find that past excess rental growth rates are predictive of future rent revisions, and that increasing steepness of the term structure of contract rents is predictive for future rent levels.



* Wan, W. and T. Lindenthal. <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3758451">"Towards Accountability in Machine Learning Applications: A System-testing Approach"</a>
  - *Abstract:* A rapidly expanding universe of technology-focused startups is trying to change and improve the way real estate markets operate. The undisputed predictive power of machine learning (ML) models often plays a crucial role in the 'disruption' of traditional processes. However, an accountability gap prevails: How do the models arrive at their predictions? Do they do what we hope they do – or are corners cut?

  Training ML models is a software development process at heart. We suggest following the dedicated software testing framework and verifying that the ML model is performing as intended. Illustratively, we augment two image classifiers with a system testing procedure based on local interpretable model-agnostic explanation (LIME) techniques. Analyzing the classifications sheds light on some of the factors that determine the behavior of the systems. We show that cross-validation is simply not good enough when operating in regulated environments.

* T. Lindenthal and C. Schmidt. "The Odd One Out: Asset Uniqueness and Price Precision"

* Ooi, J. and T. Lindenthal. <span>“</span>Local market power in residential property markets”

* Lindenthal T. and P. Eichholtz “That’s What We Paid for It: The Spell of the Home Purchase Price through the Centuries”
