---
title: "AI in higher education: Last Samurai vs Brain Rot"
date: 2026-01-27
header:
excerpt: "Today, we had a discussion about how teaching needs to evolve in these AI enabled time. As researchers and educatores we are painfully aware of two AI-related risks that sit at opposite ends of the spectrum: becoming AI Luddites, or drifting into the habits of the lazy AI slob."
---

Today, my colleagues and I had an in-depth discussion about how our teaching needs to evolve. We are painfully aware of two AI-related risks that sit at opposite ends of the spectrum: becoming AI Luddites, or drifting into the habits of the lazy AI slob.

The first risk is the AI-avoiding “Last Samurai”. This is the stance that treats AI use as inferior, even as a form of cheating, and therefore refuses to engage with it at all. For centuries, samurai culture revolved around mastery of swordsmanship, discipline, and personal honour. When firearms arrived in Japan, they were dismissed as inelegant and unworthy of a true warrior. Yet mass-produced guns quickly proved decisive. Samurai who clung to traditional mastery found themselves outpaced by armies that required less individual skill but delivered far greater collective power. Their fundamentals were impeccable; the race had simply changed. The analogy extends to Amish communities in the US who, broadly speaking, chose to avoid technologies beyond the nineteenth century. In higher education, students who never learn to work with AI tools will be slower to achieve their goals, less competitive in roles where productivity is amplified by new tools, and will miss the chance to focus on areas where humans still have a clear edge over machines.

The second risk is the opposite: **Skill atrophy** (or, a bit more graphic, **AI-induced brain rot**}. It is real, and it is already visible. Students can breeze through their education by outsourcing thinking, writing, and problem-solving to large language models. In doing so, they risk failing to develop core skills, resilience, creativity, and intellectual grit because the heavy lifting has been done for them. In this world, students struggle to draft and structure text. When fewer and fewer people can read complex texts, deep reading may be become a new superpower in an age of shallow, AI-mediated summaries. Convenience slowly erodes competence, and fluency is mistaken for understanding.

The challenge for higher education is not to choose between rejection and surrender, but to navigate a narrow path between them. We need to teach students how to use AI deliberately and critically, while still demanding genuine thinking, effort, and originality. The goal is neither the honourable but obsolete samurai, nor the complacent passenger, but graduates who can wield new tools without letting those tools replace their minds. But how exactly can we achieve this?

